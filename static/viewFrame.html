<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SpeakEasy</title>
    <style>
    html, body {
        height: 100%;
        margin: 0;
        padding: 0;
    }
    
       body {
        font-family: 'Georgia', serif;
        text-align: center;
        margin: 50px;
        background-color: #591607;
        color: #f5f5f5;
        background-image: url("static/wooden-table-with-lights-in-background-free-photo.jpg");
        background-attachment: fixed;
        background-size: cover;
        background-repeat: no-repeat;
        background-position: center;
    }

    h1 {
        font-size: 60px;
        color: #f0e6d2;
        text-shadow: 2px 2px 5px #000;
        font-family: 'Georgia', serif;
        letter-spacing: 2px;
        margin-bottom: 30px;
    }

    #controls {
    background-color: rgba(0, 0, 0, 0.7);
    padding: 30px;
    border-radius: 15px;
    display: block; /* show controls by default */
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.5);
    max-width: 600px;
    margin: auto;
    }

    #translationSection {
    display: none; /* hide on first load */
    background-color: rgba(0, 0, 0, 0.7);
    padding: 30px;
    border-radius: 15px;
    box-shadow: 0 4px 15px rgba(0, 0, 0, 0.5);
    max-width: 600px;
    margin: auto;
    }

    label, select {
        font-size: 18px;
    }

    select {
        padding: 10px;
        font-size: 16px;
        border-radius: 8px;
        border: 1px solid #c19b77;
        background-color: #3e2c24;
        color: #f5f5f5;
    }

    button {
        padding: 12px 24px;
        font-size: 18px;
        margin-top: 20px;
        border: none;
        border-radius: 10px;
        cursor: pointer;
        background-color: #7a4e2d;
        color: #f0e6d2;
        transition: background-color 0.3s, transform 0.2s;
    }

    button:hover {
        background-color: #a1623c;
        transform: scale(1.05);
    }

    .back {
        background-color: #9e2a2b;
    }

    .back:hover {
        background-color: #611111;
    }

    #feedbackText {
        font-weight: bold;
        margin-top: 15px;
        color: #ffd700;
        font-size: 20px;
        text-shadow: 1px 1px 3px #000;
    }

    #instructionText, #wordToTranslate {
        font-size: 24px;
        margin-top: 15px;
        color: #f5f5f5;
        text-shadow: 1px 1px 3px #000;
    }

    </style>
</head>
<body>
    <h1>SpeakEasy</h1>
<div id="controls">
    <!--<button onclick="startFunction()">Start</button>-->
    <button class="start">Start</button>

    
    <br><br>
    
    <label for="options">Choose a language:</label>
    <select id="options">
        <option value="French">French</option>
        <option value="Spanish">Spanish</option>
        <option value="Piglatin">Piglatin</option>
    </select>
</div>

    <div id="translationSection">
        <p id="feedbackText"></p>
        <p id="instructionText">Say the word in the selected language</p>
        <p id="wordToTranslate">test</p>
        <br><br>
        <p><strong>Audio Level:</strong> <span id="audioLevelDisplay">0 dB</span></p>
        <button class="back">Back</button>
    </div>

    <script>
        let analyser;  // Global analyser
        let audioLevelsData;  // Global audioLevelsData

        function startLesson() {
            const selectedLanguage = document.getElementById("options").value;
            const wordToTranslate = document.getElementById("wordToTranslate");

            fetch('/start-lesson', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ language: selectedLanguage })
            })
            .then(response => response.json())
            .then(data => {
                document.getElementById("controls").style.display = "none";
                document.getElementById("translationSection").style.display = "block";
                instructionText.innerText = "Say the word in the selected language";


                //setWord();
                startEventSource();  // Start listening for updates 
            })
            .catch(error => console.error('Error:', error));
        }

        function startEventSource() {
            const eventSource = new EventSource('/wordStream');

            eventSource.onmessage = function(event) {
                console.log("Received word:", event.data);
                

                if (event.data.startsWith("Correct!") || event.data.startsWith("Incorrect!")) {
                    feedbackText.innerText = event.data;
                } else {
                    wordToTranslate.innerText = event.data;

                    // this is where to put the code to output audio w/ the prompt + the word
                    // after the audio is done being output, we are ready to start listening for input, (call startRecording())
                    wordToTranslate.style.visibility = "visible";
                    fetch('/uploadAudio')
                        .then(response => response.blob())
                        .then(blob => {
                            const audioUrl = URL.createObjectURL(blob);
                            const audio = new Audio(audioUrl);
                            audio.addEventListener('ended', () => {
                                console.log('Audio finished playing');
                                startRecording(mediaRecorder)
                            });

                            audio.play();
                        })
                        .catch(error => console.error('Error fetching audio:', error));
                    }
                }
                eventSource.onerror = function() {
                    console.error("EventSource failed.");
                    eventSource.close();
                };
            };
            
            

        function setWord(){
            fetch('/get_string')
            .then(response => response.json())
            .then(data => {
                document.getElementById('wordToTranslate').innerText = data.data;
            })
            .catch(error => console.error('Error:', error));
        }

        function stopLesson() {
            fetch('/stop-lesson', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' }
            })
            .then(response => response.json())
            .catch(error => console.error('Error:', error));
        }

        function updateAudioLevels() {
            if (analyser) {
                analyser.getFloatFrequencyData(audioLevelsData);  
                
                
                let sum = 0;
                for (let i = 0; i < audioLevelsData.length; i++) {
                    sum += audioLevelsData[i];
                }
                let avgDb = sum / audioLevelsData.length;
                
                document.getElementById("audioLevelDisplay").innerText = avgDb.toFixed(2) + " dB";

                return avgDb;
            }
        }

        function startRecording(mediaRecorder) {
            mediaRecorder.start();
            console.log("recorder started");

            monitorAudioLevels();
        }

        function monitorAudioLevels() {
            let startTime = performance.now();
            let levels = [];
            let baseline;

            function sampleBaseLine() {
                let currentLevel = updateAudioLevels();
                levels.push(currentLevel);

                if (performance.now() - startTime < 500) { // Collect baseline for 500ms
                    requestAnimationFrame(sampleBaseLine);
                } else {
                    baseline = levels.reduce((sum, val) => sum + val, 0) / levels.length;
                    console.log("Baseline Audio Level:", baseline);
                    listenForSpeech(baseline);
                }
            }

            function listenForSpeech(baseline) {
                let threshold = baseline + 10; // Set a threshold above baseline to detect speech
                let silenceDuration = 1000; // Silence time required to confirm speech has ended (1 sec)
                let speechStarted = false;
                let lastSpeechTime = 0;

                function detectSpeech() {
                    let currentLevel = updateAudioLevels();
                    let now = performance.now();

                    if (currentLevel > threshold) {
                        if (!speechStarted) {
                            console.log("Speech detected!");
                            speechStarted = true;
                        }
                        lastSpeechTime = now; // Reset silence timer
                    } else if (speechStarted && now - lastSpeechTime > silenceDuration) {
                        console.log("Speech ended, stopping recording.");
                        stopRecording(mediaRecorder);
                        return; 
                    }

                    if (now - startTime < 5000) { // 5 seconds max listening time
                        requestAnimationFrame(detectSpeech);
                    } 
                    else {
                        console.log("Max time reached, stopping recording.");
                        stopRecording(mediaRecorder);
                    }
                }

                detectSpeech();
            }

            sampleBaseLine();
        }
        

        function stopRecording(mediaRecorder) {
            wordToTranslate.style.visibility = "hidden";
            mediaRecorder.stop();
            console.log(mediaRecorder.state);
            console.log("recorder stopped");
            document.getElementById("feedbackText").innerText = "Processing...";
        }

        function handleStop(chunks) {
            const blob = new Blob(chunks, { type: 'audio/webm' });
            const file = new File([blob], "userAudio.webm", { type: 'audio/webm' });

            const formData = new FormData();
            formData.append('audio_file', file);

            fetch('/upload-audio', {
                method: 'POST',
                body: formData
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error("Failed to upload audio");
                }
                return response.text();
            })
            .then(feedback => {
                console.log("Feedback received:", feedback);
                document.getElementById("feedbackText").innerText = feedback;

            })
            .catch(error => console.error('Error uploading file:', error));
        }

        const start = document.querySelector(".start");
        const startRecord = document.querySelector(".startRecord");
        const back = document.querySelector(".back");

        start.addEventListener("click", () => {
            wordToTranslate.style.visibility = "visible";
            startLesson();
            document.getElementById("controls").style.display = "none";
            document.getElementById("translationSection").style.display = "block";
            instructionText.innerText = "Say the word in the selected language";
        });

        back.addEventListener("click", () => {
            stopLesson();
            document.getElementById("controls").style.display = "block";
            document.getElementById("translationSection").style.display = "none";
        });

        let mediaRecorder;

        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            console.log("getUserMedia supported.");
            navigator.mediaDevices.getUserMedia({audio: true})
            .then((stream) => {
                mediaRecorder = new MediaRecorder(stream);

                const audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();  // Assign to global analyser
                source.connect(analyser);

                analyser.fftSize = 512;  // Adjust for resolution
                analyser.smoothingTimeConstant = 0.8;

                audioLevelsData = new Float32Array(analyser.fftSize);  // Assign to global audioLevelsData

                let audioChunks = [];

                mediaRecorder.addEventListener("dataavailable", (event) => {
                    audioChunks.push(event.data);
                });

                mediaRecorder.addEventListener("stop", () => {
                    handleStop(audioChunks);
                });

                startRecord.addEventListener("click", () => {
                    audioChunks = [];
                    startRecording(mediaRecorder);
                });
            });
        } else {
            console.log("getUserMedia not supported on your browser!");
        }

    </script>
</body>
</html>